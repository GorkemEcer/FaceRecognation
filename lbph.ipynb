{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "def preprocess_image(image):\n",
    "    # Görüntüyü gri tonlamaya çevir\n",
    "    #gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Gaussian Blur uygula\n",
    "    blurred_image = cv2.medianBlur(image, ksize=5)\n",
    "    \n",
    "    blurred_image = cv2.resize(blurred_image, (64, 64))\n",
    "    \n",
    "    return blurred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(image):\n",
    "    winSize = (64,64)\n",
    "    blockSize = (16,16)\n",
    "    blockStride = (8,8)\n",
    "    cellSize = (8,8)\n",
    "    nbins = 9\n",
    "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins)\n",
    "    h = hog.compute(image)\n",
    "    return h.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_geometric_features(landmarks):\n",
    "    features = []\n",
    "    if landmarks is not None:\n",
    "        # Gözler arası mesafe\n",
    "        eye_distance = np.linalg.norm(landmarks[36] - landmarks[45])\n",
    "        features.append(eye_distance)\n",
    "        # Burun uzunluğu\n",
    "        nose_length = np.linalg.norm(landmarks[27] - landmarks[33])\n",
    "        features.append(nose_length)\n",
    "        # Ağız genişliği\n",
    "        mouth_width = np.linalg.norm(landmarks[48] - landmarks[54])\n",
    "        features.append(mouth_width)\n",
    "        # Diğer özellikler...\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "def extract_lbp_features(image, P=8, R=1):\n",
    "    # Görüntüyü gri tonlamaya çevir\n",
    "    image_gray = rgb2gray(image)\n",
    "    # LBP uygula\n",
    "    lbp = local_binary_pattern(image_gray, P, R, method=\"uniform\")\n",
    "    # Histogramı hesapla ve normalize et\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from collections import Counter\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "\n",
    "def read_and_split_data(directory_path, test_size=0.2):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_names = []\n",
    "    combined_features_list = []\n",
    "    random.seed(43)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for dir in dirs:\n",
    "            current_dir_path = os.path.join(root, dir)\n",
    "            image_files = [f for f in os.listdir(current_dir_path) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "            # Select a random subset of images if needed\n",
    "            #selected_files = random.sample(image_files, min(len(image_files), 100))\n",
    "            \n",
    "            for file in image_files:\n",
    "                image_path = os.path.join(current_dir_path, file)\n",
    "                image = cv2.imread(image_path)\n",
    "                \n",
    "                if image is not None:\n",
    "                    faces = face_cascade.detectMultiScale(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), 1.1, 4)\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        face_img = image[y:y+h, x:x+w]\n",
    "                        face_img = preprocess_image(face_img)\n",
    "                        hog_features = calculate_geometric_features(face_img)\n",
    "                        combined_features_list.append(hog_features)\n",
    "                        labels.append(dir)\n",
    "            if dir not in label_names:\n",
    "                label_names.append(dir)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(combined_features_list, labels, test_size=test_size, stratify=labels)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_split_data_lpb(directory_path, test_size=0.2):\n",
    "    combined_features_list = []\n",
    "    labels = []\n",
    "    label_names = []\n",
    "    random.seed(43)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for dir in dirs:\n",
    "            current_dir_path = os.path.join(root, dir)\n",
    "            image_files = [f for f in os.listdir(current_dir_path) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "            \n",
    "            for file in image_files:\n",
    "                image_path = os.path.join(current_dir_path, file)\n",
    "                image = cv2.imread(image_path)\n",
    "                \n",
    "                if image is not None:\n",
    "                    faces = face_cascade.detectMultiScale(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), 1.1, 4)\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        face_img = image[y:y+h, x:x+w]\n",
    "                        face_img = preprocess_image(face_img)  # preprocess_image fonksiyonunun tanımını sağlamalısınız.\n",
    "                        lbp_features = extract_lbp_features(face_img)\n",
    "                        combined_features_list.append(lbp_features)\n",
    "                        labels.append(dir)\n",
    "            if dir not in label_names:\n",
    "                label_names.append(dir)\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(combined_features_list, labels, test_size=test_size, stratify=labels)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "def calculate_accuracy(X_train, y_train, X_test, y_test):\n",
    "    lda = LDA(n_components=min(len(np.unique(y_train))-1, len(X_train[0])))\n",
    "    X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "    X_test_lda = lda.transform(X_test)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=30)\n",
    "    knn.fit(X_train_lda, y_train)\n",
    "    y_pred = knn.predict(X_test_lda)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    best_svm = SVC(C=1000.0, class_weight='balanced', gamma=0.01)\n",
    "    best_svm.fit(X_train_lda, y_train)\n",
    "\n",
    "    # Make predictions with the best SVM\n",
    "    y_pred_svm = best_svm.predict(X_test_lda)\n",
    "\n",
    "    # Calculate and return the accuracy for SVM\n",
    "    accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "    return accuracy,accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculate_accuracy_with_svm(X_train, y_train, X_test, y_test):\n",
    "    # LDA nesnesini başlat ve n_components ayarla\n",
    "    lda = LDA(n_components=min(len(np.unique(y_train))-1, len(X_train[0])))\n",
    "    \n",
    "    # Eğitim verisi üzerinde LDA'yı fit edin ve dönüştürme uygulayın\n",
    "    X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "    \n",
    "    # Test verisini LDA ile dönüştürün\n",
    "    X_test_lda = lda.transform(X_test)\n",
    "    \n",
    "    # SVM sınıflandırıcısını başlat\n",
    "    svm = SVC(kernel='linear')  # Kernel tipi olarak 'linear' kullanıldı, ihtiyaca göre 'rbf' veya başka bir kernel seçilebilir\n",
    "    \n",
    "    # Eğitim verisi üzerinde SVM'yi fit edin\n",
    "    svm.fit(X_train_lda, y_train)\n",
    "    \n",
    "    # Test verisi üzerinde tahmin yap\n",
    "    y_pred = svm.predict(X_test_lda)\n",
    "    \n",
    "    # Doğruluk oranını hesapla\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "def calculate_accuracy_with_pca(X_train, y_train, X_test, y_test):\n",
    "    # PCA nesnesini başlatın. n_components, azaltılmış özellik uzayının boyutunu belirler.\n",
    "    # Örneğin, veri setinizin varyansının büyük bir kısmını korumak için 0.95 gibi bir değer kullanabilirsiniz.\n",
    "    lda = LDA(n_components=min(len(np.unique(y_train))-1, len(X_train[1])))\n",
    "    X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "    X_test_lda = lda.transform(X_test)\n",
    "\n",
    "    X_train = np.array(X_train_lda)\n",
    "    X_test = np.array(X_test_lda)\n",
    "    #pca = PCA(n_components=105)\n",
    "    \n",
    "    pca = PCA(n_components=104, svd_solver='randomized', whiten=True).fit(X_train)\n",
    "    # Eğitim verisi üzerinde PCA'yı fit edin ve dönüşümü uygulayın\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "    # Test verisini dönüştürün\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    # KNN sınıflandırıcısını başlatın\n",
    "    knn = KNeighborsClassifier(n_neighbors=30)\n",
    "\n",
    "    # Eğitim verisi üzerinde KNN'yi fit edin\n",
    "    knn.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Test verisi üzerinde tahmin yapın\n",
    "    y_pred = knn.predict(X_test_pca)\n",
    "\n",
    "    # Doğruluk oranını hesaplayın\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    best_svm = SVC(C=1000.0, class_weight='balanced', gamma=0.01)\n",
    "    best_svm.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Make predictions with the best SVM\n",
    "    y_pred_svm = best_svm.predict(X_test_pca)\n",
    "\n",
    "    # Calculate and return the accuracy for SVM\n",
    "    accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "    return accuracy, accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def calculate_accuracy_with_rf(X_train, y_train, X_test, y_test):\n",
    "    # LDA ile boyut indirgeme\n",
    "    lda = LDA(n_components=min(len(np.unique(y_train))-1, len(X_train[0])))\n",
    "    X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "    X_test_lda = lda.transform(X_test)\n",
    "\n",
    "    # Random Forest sınıflandırıcısını başlat\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)  # n_estimators, ormanınızdaki ağaç sayısıdır\n",
    "\n",
    "    # Eğitim verisi üzerinde Random Forest'ı eğit\n",
    "    rf.fit(X_train_lda, y_train)\n",
    "\n",
    "    # Test verisi üzerinde tahmin yap\n",
    "    y_pred = rf.predict(X_test_lda)\n",
    "\n",
    "    # Doğruluk oranını hesapla\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_split_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m105_classes_pins_dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[52], line 42\u001b[0m, in \u001b[0;36mread_and_split_data\u001b[1;34m(directory_path, test_size)\u001b[0m\n\u001b[0;32m     40\u001b[0m face_img \u001b[38;5;241m=\u001b[39m image[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw]\n\u001b[0;32m     41\u001b[0m face_img \u001b[38;5;241m=\u001b[39m preprocess_image(face_img)\n\u001b[1;32m---> 42\u001b[0m hog_features \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_geometric_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m combined_features_list\u001b[38;5;241m.\u001b[39mappend(hog_features)\n\u001b[0;32m     44\u001b[0m labels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mdir\u001b[39m)\n",
      "Cell \u001b[1;32mIn[50], line 14\u001b[0m, in \u001b[0;36mcalculate_geometric_features\u001b[1;34m(landmarks)\u001b[0m\n\u001b[0;32m     12\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(mouth_width)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Diğer özellikler...\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = read_and_split_data(\"105_classes_pins_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy Etiket: 0.02254684026675135 With SVM:  0.0219117180057161\n"
     ]
    }
   ],
   "source": [
    "accuracy,accuracy_svm = calculate_accuracy(X_train, y_train, X_test, y_test)\n",
    "print(\"accuracy Etiket:\", accuracy, \"With SVM: \",accuracy_svm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
